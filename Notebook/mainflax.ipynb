{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random\n",
    "from jax.nn import pad\n",
    "from epiweeks import Week, Year\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "dtype = torch.float\n",
    "WEEKS_AHEAD = 4\n",
    "PAD_VALUE = -999\n",
    "DAYS_IN_WEEK = 7\n",
    "NOISE_LEVELS_FLU = [0.15, 0.25, 0.50, 0.75]\n",
    "NOISE_LEVELS_COVID = [0.5, 1.0, 1.5, 2.0]\n",
    "from flax import linen as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pdb\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import flax\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from abc import ABC, abstractmethod\n",
    "from scipy.stats import gamma\n",
    "import math\n",
    "from flax import functional as F\n",
    "import yaml\n",
    "INITIAL_INFECTED_RATIO = 0.5\n",
    "INFINITY_TIME = np.inf\n",
    "USE_SPARSE = False\n",
    "import random\n",
    "import jax.nn as nn\n",
    "import time\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from epiweeks import Week\n",
    "import argparse\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import traceback\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/kaggle/input/gradabmdata/Data/Processed/covid_data.csv\"\n",
    "county_datapath = f\"/kaggle/input/gradabmdata/Data/Processed/county_data.csv\"\n",
    "datapath_flu_hhs = \"/kaggle/input/gradabmdata/Data/Processed/flu_region_data.csv\"\n",
    "datapath_flu_state = \"/kaggle/input/gradabmdata/Data/Processed/flu_state_data.csv\"\n",
    "population_path = \"/kaggle/input/gradabmdata/Data/ABM_parameters/table_population.csv\"\n",
    "EW_START_DATA = \"202012\"\n",
    "EW_START_DATA_FLU = \"201740\"  # for convenience\n",
    "\n",
    "# Select signals COVID\n",
    "macro_features = [\n",
    "    \"retail_and_recreation_percent_change_from_baseline\",\n",
    "    \"grocery_and_pharmacy_percent_change_from_baseline\",\n",
    "    \"parks_percent_change_from_baseline\",\n",
    "    \"transit_stations_percent_change_from_baseline\",\n",
    "    \"workplaces_percent_change_from_baseline\",\n",
    "    \"residential_percent_change_from_baseline\",\n",
    "    \"apple_mobility\",\n",
    "    \"death_jhu_incidence\",\n",
    "    \"positiveIncr\",\n",
    "]\n",
    "\n",
    "# Select signals Flu\n",
    "include_cols = [\n",
    "    \"symptom:Fever\",\n",
    "    \"symptom:Low-grade fever\",\n",
    "    \"symptom:Cough\",\n",
    "    \"symptom:Sore throat\",\n",
    "    \"symptom:Headache\",\n",
    "    \"symptom:Fatigue\",\n",
    "    \"symptom:Vomiting\",\n",
    "    \"symptom:Diarrhea\",\n",
    "    \"symptom:Shortness of breath\",\n",
    "    \"symptom:Chest pain\",\n",
    "    \"symptom:Dizziness\",\n",
    "    \"symptom:Confusion\",\n",
    "    \"symptom:Generalized tonicâ€“clonic seizure\",\n",
    "    \"symptom:Weakness\",\n",
    "]\n",
    "\n",
    "states = [\n",
    "    \"AL\",\n",
    "    \"AK\",\n",
    "    \"AZ\",\n",
    "    \"AR\",\n",
    "    \"CA\",\n",
    "    \"CO\",\n",
    "    \"CT\",\n",
    "    \"DE\",\n",
    "    \"DC\",\n",
    "    \"FL\",\n",
    "    \"GA\",\n",
    "    \"ID\",\n",
    "    \"IL\",\n",
    "    \"IN\",\n",
    "    \"IA\",\n",
    "    \"KS\",\n",
    "    \"KY\",\n",
    "    \"LA\",\n",
    "    \"ME\",\n",
    "    \"MD\",\n",
    "    \"MA\",\n",
    "    \"MI\",\n",
    "    \"MN\",\n",
    "    \"MS\",\n",
    "    \"MO\",\n",
    "    \"MT\",\n",
    "    \"NE\",\n",
    "    \"NV\",\n",
    "    \"NH\",\n",
    "    \"NJ\",\n",
    "    \"NM\",\n",
    "    \"NY\",\n",
    "    \"NC\",\n",
    "    \"ND\",\n",
    "    \"OH\",\n",
    "    \"OK\",\n",
    "    \"OR\",\n",
    "    \"PA\",\n",
    "    \"RI\",\n",
    "    \"SC\",\n",
    "    \"SD\",\n",
    "    \"TN\",\n",
    "    \"TX\",\n",
    "    \"UT\",\n",
    "    \"VT\",\n",
    "    \"VA\",\n",
    "    \"WA\",\n",
    "    \"WV\",\n",
    "    \"WI\",\n",
    "    \"WY\",\n",
    "    \"X\",\n",
    "]\n",
    "\n",
    "counties = {\n",
    "    \"MA\": [\n",
    "        \"25003\",\n",
    "#         \"25005\",\n",
    "        \"25009\",\n",
    "        \"25011\",\n",
    "        \"25013\",\n",
    "        \"25015\",\n",
    "        \"25021\",\n",
    "        \"25023\",\n",
    "        \"25027\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "########################################################\n",
    "#           helpers\n",
    "########################################################\n",
    "\n",
    "def convert_to_epiweek(x):\n",
    "    return Week.fromstring(str(x))\n",
    "\n",
    "\n",
    "def get_epiweeks_list(start_ew, end_ew):\n",
    "    \"\"\"\n",
    "    Returns a list of epiweeks objects between start_ew and end_ew (inclusive).\n",
    "    This is useful for iterating through these weeks.\n",
    "    \"\"\"\n",
    "    if isinstance(start_ew, str):\n",
    "        start_ew = convert_to_epiweek(start_ew)\n",
    "    if isinstance(end_ew, str):\n",
    "        end_ew = convert_to_epiweek(end_ew)\n",
    "    iter_weeks = (\n",
    "        list(Year(2017).iterweeks())\n",
    "        + list(Year(2018).iterweeks())\n",
    "        + list(Year(2019).iterweeks())\n",
    "        + list(Year(2020).iterweeks())\n",
    "        + list(Year(2021).iterweeks())\n",
    "    )\n",
    "    idx_start = iter_weeks.index(start_ew)\n",
    "    idx_end = iter_weeks.index(end_ew)\n",
    "    return iter_weeks[idx_start : idx_end + 1]\n",
    "\n",
    "\n",
    "def create_window_seqs(X, y, min_sequence_length):\n",
    "    \"\"\"\n",
    "    Creates windows of fixed size with appended zeros.\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: Targets, in synchrony with features (i.e. x[t] and y[t] correspond to the same time)\n",
    "        min_sequence_length: Minimum length of the sequence\n",
    "    \"\"\"\n",
    "    # Convert to small sequences for training, starting with length 10\n",
    "    seqs = []\n",
    "    targets = []\n",
    "    mask_ys = []\n",
    "\n",
    "    # Starts at sequence_length and goes until the end\n",
    "    for idx in range(min_sequence_length, X.shape[0] + 1, 1):\n",
    "        # Sequences\n",
    "        seqs.append(np.array(X[:idx, :]))\n",
    "        # Targets\n",
    "        y_ = y[:idx]\n",
    "        mask_y = np.ones(len(y_))\n",
    "        targets.append(np.array(y_))\n",
    "        mask_ys.append(mask_y)\n",
    "    seqs = pad_sequence(seqs, batch_first=True, padding_value=0).type(dtype)\n",
    "    ys = pad_sequence(targets, batch_first=True, padding_value=PAD_VALUE).type(dtype)\n",
    "    mask_ys = pad_sequence(mask_ys, batch_first=True, padding_value=0).type(dtype)\n",
    "\n",
    "    return seqs, ys, mask_ys\n",
    "\n",
    "########################################################\n",
    "#           COVID: state/national level data\n",
    "########################################################\n",
    "\n",
    "def load_df(region, ew_start_data, ew_end_data):\n",
    "    \"\"\"Load and clean data.\"\"\"\n",
    "    df = pd.read_csv(datapath, low_memory=False)\n",
    "    df = df[(df[\"region\"] == region)]\n",
    "    df[\"epiweek\"] = df.loc[:, \"epiweek\"].apply(convert_to_epiweek)\n",
    "    # Subset data using init parameters\n",
    "    df = df[(df[\"epiweek\"] <= ew_end_data) & (df[\"epiweek\"] >= ew_start_data)]\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    df = df.fillna(method=\"backfill\")\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_state_train_data(region, pred_week, ew_start_data=EW_START_DATA):\n",
    "    \"\"\"Get processed dataframe of data + target as array.\"\"\"\n",
    "    # Import data\n",
    "    region = str.upper(region)\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    ew_start_data = convert_to_epiweek(ew_start_data)\n",
    "    df = load_df(region, ew_start_data, pred_week)\n",
    "    # Select targets\n",
    "    targets = df.loc[:, [\"positiveIncr\"]].values\n",
    "    # Now subset based on input ew_start_data\n",
    "    df = df[macro_features]\n",
    "    return df, targets\n",
    "\n",
    "\n",
    "def get_state_test_data(region, pred_week):\n",
    "    \"\"\"\n",
    "    @param pred_week: Prediction week\n",
    "    \"\"\"\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    # Import smoothed dataframe\n",
    "    df = load_df(region, pred_week + 1, pred_week + 4)\n",
    "    new_cases = df.loc[:, \"positiveIncr\"].values\n",
    "    new_deaths = df.loc[:, \"death_jhu_incidence\"].values\n",
    "    return new_cases, new_deaths\n",
    "\n",
    "\n",
    "def get_train_targets_all_regions(pred_week):\n",
    "    deaths_all_regions = {}\n",
    "    for region in states:\n",
    "        _, targets = get_state_train_data(region, pred_week)\n",
    "        deaths_all_regions[region] = targets[:, 0]  # index 0 is inc positive cases\n",
    "    return deaths_all_regions\n",
    "\n",
    "\n",
    "def get_train_features_all_regions(pred_week):\n",
    "    features_all_regions = {}\n",
    "    for region in states:\n",
    "        df, _ = get_state_train_data(region, pred_week)\n",
    "        features_all_regions[region] = df.to_numpy()\n",
    "    return features_all_regions\n",
    "\n",
    "########################################################\n",
    "#           COVID: county level data\n",
    "# note: to obtain data, use get_features_per_county.ipynb\n",
    "########################################################\n",
    "\n",
    "def load_county_df(county, ew_start_data, ew_end_data):\n",
    "    \"\"\"Load and clean data\"\"\"\n",
    "    df = pd.read_csv(county_datapath)\n",
    "    df = df[(df[\"geo_value\"] == int(county))]\n",
    "\n",
    "    def convert_date_to_epiweek(x):\n",
    "        if isinstance(x, Week):\n",
    "            return x\n",
    "        else:\n",
    "            date = datetime.strptime(x, \"%Y-%m-%d\")\n",
    "            return Week.fromdate(date)\n",
    "\n",
    "    df[\"epiweek\"] = df.loc[:, \"time_value\"].apply(convert_date_to_epiweek)\n",
    "    # Subset data using init parameters\n",
    "    df = df[(df[\"epiweek\"] <= ew_end_data) & (df[\"epiweek\"] >= ew_start_data)]\n",
    "    df = df.fillna(0)  # There are zeros at the beginning\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_county_train_data(\n",
    "    county, pred_week, ew_start_data=EW_START_DATA, noise_level=0\n",
    "):\n",
    "    \"\"\"Get processed dataframe of data + target as array\"\"\"\n",
    "    # Import data\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    ew_start_data = convert_to_epiweek(ew_start_data)\n",
    "    df = load_county_df(county, ew_start_data, pred_week)\n",
    "    # Select targets\n",
    "    targets = df.loc[:, [\"cases\", \"deaths\"]].values\n",
    "    if noise_level > 0:\n",
    "        # noise_level is an index for your list\n",
    "        noise = NOISE_LEVELS_COVID[noise_level - 1]\n",
    "        std_vals = np.std(targets, axis=0) * noise\n",
    "        noise_dist = np.random.normal(scale=std_vals, size=targets.shape)\n",
    "        noisy_targets = targets + noise_dist\n",
    "        noisy_targets = noisy_targets.astype(\"int32\")\n",
    "        targets = np.maximum(noisy_targets, 0)\n",
    "    df.drop(columns=[\"epiweek\", \"geo_value\", \"time_value\"], inplace=True)\n",
    "    return df, targets\n",
    "\n",
    "\n",
    "def get_county_test_data(county, pred_week):\n",
    "    \"\"\"\n",
    "    @param pred_week: Prediction week\n",
    "    \"\"\"\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    # Import smoothed dataframe\n",
    "    df = load_county_df(county, pred_week, pred_week + 4)\n",
    "    new_cases = df.loc[:, \"cases\"].values\n",
    "    new_deaths = df.loc[:, \"deaths\"].values\n",
    "    return new_cases, new_deaths\n",
    "\n",
    "########################################################\n",
    "#           FLU: regional/state/national level data\n",
    "########################################################\n",
    "\n",
    "def load_df_flu(region, ew_start_data, ew_end_data, geo):\n",
    "    \"\"\"Load and clean data\"\"\"\n",
    "    if geo == \"hhs\":\n",
    "        datapath = datapath_flu_hhs\n",
    "    elif geo == \"state\":\n",
    "        datapath = datapath_flu_state\n",
    "    else:\n",
    "        raise ValueError(\"geo must be hhs or state\")\n",
    "    df = pd.read_csv(datapath, low_memory=False)\n",
    "\n",
    "    df = df[(df[\"region\"] == region)]\n",
    "    df[\"epiweek\"] = df.loc[:, \"epiweek\"].apply(convert_to_epiweek)\n",
    "    # Subset data using init parameters\n",
    "    df = df[(df[\"epiweek\"] <= ew_end_data) & (df[\"epiweek\"] >= ew_start_data)]\n",
    "    df = df.fillna(method=\"ffill\")\n",
    "    df = df.fillna(method=\"backfill\")\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_state_train_data_flu(\n",
    "    region, pred_week, ew_start_data=EW_START_DATA_FLU, geo=\"state\", noise_level=0\n",
    "):\n",
    "    \"\"\"Get processed dataframe of data + target as array\"\"\"\n",
    "    # Import data\n",
    "    region = str.upper(region)\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    ew_start_data = convert_to_epiweek(ew_start_data)\n",
    "    df = load_df_flu(region, ew_start_data, pred_week, geo)\n",
    "    # Select targets\n",
    "    targets = df[\"ili\"].astype(float).values.reshape(-1, 1)  # We need this 2d\n",
    "    if noise_level > 0:\n",
    "        # noise_level is an index for your list\n",
    "        noise = NOISE_LEVELS_FLU[noise_level - 1]\n",
    "        NOISE_STD = targets.std() * noise\n",
    "        noise_dist = np.random.normal(loc=0, scale=NOISE_STD, size=targets.shape)\n",
    "        noisy_targets = targets + noise_dist\n",
    "        targets = np.array([max(ix, 0) for ix in noisy_targets])\n",
    "    # Now subset based on input ew_start_data\n",
    "    df = df[[\"month\"] + include_cols]\n",
    "    return df, targets\n",
    "\n",
    "\n",
    "def get_state_test_data_flu(region, pred_week, geo=\"state\"):\n",
    "    \"\"\"\n",
    "    @param pred_week: Prediction week\n",
    "    \"\"\"\n",
    "    pred_week = convert_to_epiweek(pred_week)\n",
    "    # Import smoothed dataframe\n",
    "    df = load_df_flu(region, pred_week + 1, pred_week + 4, geo)\n",
    "    ili = df.loc[:, \"ili\"].values\n",
    "    return ili\n",
    "\n",
    "\n",
    "def get_dir_from_path_list(path):\n",
    "    outdir = path[0]\n",
    "    if not (os.path.exists(outdir)):\n",
    "        os.makedirs(outdir)\n",
    "    for p in path[1:]:\n",
    "        outdir = os.path.join(outdir, p)\n",
    "        if not (os.path.exists(outdir)):\n",
    "            os.makedirs(outdir)\n",
    "    return outdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "SMOOTH_WINDOW = 7\n",
    "\n",
    "class TransformerAttn(nn.Module):\n",
    "    \"\"\"\n",
    "    Module that calculates self-attention weights using transformer-like attention\n",
    "    \"\"\"\n",
    "\n",
    "    dim_in: int\n",
    "    value_dim: int\n",
    "    key_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.value_layer = nn.Dense(self.value_dim)\n",
    "        self.query_layer = nn.Dense(self.value_dim)\n",
    "        self.key_layer = nn.Dense(self.key_dim)\n",
    "\n",
    "    def __call__(self, seq):\n",
    "        seq_in = seq.transpose((1, 0, 2))\n",
    "        value = self.value_layer(seq_in)\n",
    "        query = self.query_layer(seq_in)\n",
    "        keys = self.key_layer(seq_in)\n",
    "        weights = (jnp.matmul(value, query.transpose((0, 2, 1)))) / jnp.sqrt(seq.shape[-1])\n",
    "        weights = nn.softmax(weights, axis=-1)\n",
    "        return jnp.matmul(weights, keys).transpose((1, 0, 2))\n",
    "\n",
    "    def forward_mask(self, seq, mask):\n",
    "        seq_in = seq.transpose((1, 0, 2))\n",
    "        value = self.value_layer(seq_in)\n",
    "        query = self.query_layer(seq_in)\n",
    "        keys = self.key_layer(seq_in)\n",
    "        weights = (jnp.matmul(value, query.transpose((0, 2, 1)))) / jnp.sqrt(seq.shape[-1])\n",
    "        weights = jnp.exp(weights)\n",
    "        weights = (weights.transpose((1, 2, 0)) * mask.transpose((1, 0))).transpose((1, 2, 0))\n",
    "        weights = weights / (weights.sum(-1, keepdims=True))\n",
    "        return jnp.matmul(weights, keys).transpose((1, 0, 2)) * mask\n",
    "\n",
    "\n",
    "class EmbedAttenSeq(nn.Module):\n",
    "    \"\"\"\n",
    "    Module to embed a sequence. Adds Attention module.\n",
    "    \"\"\"\n",
    "\n",
    "    dim_seq_in: int\n",
    "    dim_metadata: int\n",
    "    rnn_out: int\n",
    "    dim_out: int\n",
    "    n_layers: int\n",
    "    bidirectional: bool\n",
    "    attn = TransformerAttn\n",
    "    dropout: float\n",
    "\n",
    "    def setup(self):\n",
    "        self.rnn = nn.GRU(\n",
    "            self.rnn_out // 2 if self.bidirectional else self.rnn_out,\n",
    "            num_layers=self.n_layers,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.attn_layer = self.attn\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.Dense(self.dim_out),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(self.dropout),\n",
    "        )\n",
    "\n",
    "    def forward_mask(self, seqs, metadata, mask):\n",
    "        latent_seqs = self.rnn(seqs)[0]\n",
    "        latent_seqs = latent_seqs\n",
    "        latent_seqs = self.attn_layer.forward_mask(latent_seqs, mask)\n",
    "        latent_seqs = jnp.sum(latent_seqs, axis=0)\n",
    "        out = self.out_layer(jnp.concatenate([latent_seqs, metadata], axis=1))\n",
    "        return out\n",
    "\n",
    "    def forward(self, seqs, metadata):\n",
    "        latent_seqs, encoder_hidden = self.rnn(seqs)\n",
    "        latent_seqs = self.attn_layer(latent_seqs).sum(0)\n",
    "        out = self.out_layer(jnp.concatenate([latent_seqs, metadata], axis=1))\n",
    "        return out, encoder_hidden\n",
    "\n",
    "\n",
    "class DecodeSeq(nn.Module):\n",
    "    \"\"\"\n",
    "    Module to embed a sequence. Adds Attention module.\n",
    "    \"\"\"\n",
    "\n",
    "    dim_seq_in: int\n",
    "    dim_metadata: int\n",
    "    rnn_out: int\n",
    "    dim_out: int\n",
    "    n_layers: int\n",
    "    bidirectional: bool\n",
    "    dropout: float\n",
    "\n",
    "    def setup(self):\n",
    "        self.act_fcn = nn.Tanh()\n",
    "        self.embed_input = nn.Dense(self.rnn_out)\n",
    "        self.attn_combine = nn.Dense(self.rnn_out)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.rnn_out // 2 if self.bidirectional else self.rnn_out,\n",
    "            num_layers=self.n_layers,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.Dense(self.dim_out),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(self.dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, Hi_data, encoder_hidden, context):\n",
    "        inputs = Hi_data.transpose((1, 0, 2))\n",
    "        if self.bidirectional:\n",
    "            h0 = encoder_hidden[2:].transpose((1, 0, 2))\n",
    "        else:\n",
    "            h0 = jnp.stack(encoder_hidden[2:], axis=0).sum(0).unsqueeze(0)\n",
    "        inputs = self.embed_input(inputs)\n",
    "        context = jnp.tile(context, (inputs.shape[0], 1, 1))\n",
    "        inputs = jnp.concatenate((inputs, context), axis=2)\n",
    "        inputs = self.attn_combine(inputs)\n",
    "        latent_seqs, _ = self.rnn(inputs, h0)\n",
    "        latent_seqs = latent_seqs.transpose((1, 0, 2))\n",
    "        latent_seqs = self.out_layer(latent_seqs)\n",
    "        return latent_seqs\n",
    "\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return jnp.array(pd.Series(x).rolling(w, min_periods=1).mean().values)\n",
    "\n",
    "\n",
    "def fetch_county_data_covid(\n",
    "    state=\"MA\", county_id=\"25005\", pred_week=\"202021\", batch_size=32, noise_level=0\n",
    "):\n",
    "    np.random.seed(17)\n",
    "\n",
    "    if county_id == \"all\":\n",
    "        all_counties = counties[state]\n",
    "    else:\n",
    "        all_counties = [county_id]\n",
    "\n",
    "    c_seqs = []\n",
    "    c_ys = []\n",
    "    for county in all_counties:\n",
    "        X_county, y = get_county_train_data(county, pred_week, noise_level=noise_level)\n",
    "        y = moving_average(y[:, 1].ravel(), SMOOTH_WINDOW).reshape(-1, 1)\n",
    "        c_seqs.append(X_county.to_numpy())\n",
    "        c_ys.append(y)\n",
    "    c_seqs = jnp.array(c_seqs)\n",
    "    c_ys = jnp.array(c_ys)\n",
    "\n",
    "    scalers = [StandardScaler() for _ in range(len(all_counties))]\n",
    "    c_seqs_norm = []\n",
    "    for i, scaler in enumerate(scalers):\n",
    "        c_seqs_norm.append(scaler.fit_transform(c_seqs[i]))\n",
    "    c_seqs_norm = jnp.array(c_seqs_norm)\n",
    "\n",
    "    county_idx = {r: i for i, r in enumerate(all_counties)}\n",
    "\n",
    "    def one_hot(idx, dim=len(county_idx)):\n",
    "        ans = jnp.zeros(dim, dtype=jnp.float32)\n",
    "        ans = ans.at[idx].set(1.0)\n",
    "        return ans\n",
    "\n",
    "    metadata = jnp.array([one_hot(county_idx[r]) for r in all_counties])\n",
    "\n",
    "    min_sequence_length = 20\n",
    "    metas, seqs, y, y_mask = [], [], [], []\n",
    "    for meta, seq, ys in zip(metadata, c_seqs_norm, c_ys):\n",
    "        seq, ys, ys_mask = create_window_seqs(seq, ys, min_sequence_length)\n",
    "        metas.append(meta)\n",
    "        seqs.append(seq[[-1]])\n",
    "        y.append(ys[[-1]])\n",
    "        y_mask.append(ys_mask[[-1]])\n",
    "\n",
    "    all_metas = jnp.array(metas, dtype=jnp.float32)\n",
    "    all_county_seqs = jnp.concatenate(seqs, axis=0)\n",
    "    all_county_ys = jnp.concatenate(y, axis=0)\n",
    "    all_county_y_mask = jnp.concatenate(y_mask, axis=0)\n",
    "\n",
    "    counties_train, metas_train, X_train, y_train, y_mask_train = (\n",
    "        all_counties,\n",
    "        all_metas,\n",
    "        all_county_seqs,\n",
    "        all_county_ys,\n",
    "        all_county_y_mask,\n",
    "    )\n",
    "\n",
    "    train_dataset = SeqData(counties_train, metas_train, X_train, y_train, y_mask_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    seqlen = all_county_seqs.shape[1]\n",
    "    return train_loader, metas_train.shape[1], X_train.shape[2], seqlen\n",
    "\n",
    "class SeqData(torch.utils.data.Dataset):\n",
    "    def __init__(self, counties, metas, seqs, ys, ys_mask):\n",
    "        self.counties = counties\n",
    "        self.metas = metas\n",
    "        self.seqs = seqs\n",
    "        self.ys = ys\n",
    "        self.ys_mask = ys_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.counties)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        county = self.counties[index]\n",
    "        meta = self.metas[index]\n",
    "        seq = self.seqs[index]\n",
    "        y = self.ys[index]\n",
    "        y_mask = self.ys_mask[index]\n",
    "        return county, meta, seq, y, y_mask\n",
    "\n",
    "class ODE(nn.Module):\n",
    "    def __init__(self, params, device):\n",
    "        super(ODE, self).__init__()\n",
    "        county_id = params[\"county_id\"]\n",
    "        abm_params = f\"/kaggle/input/gradabmdata/Data/{county_id}_generated_params.yaml\"\n",
    "        # Reading params\n",
    "        with open(abm_params, \"r\") as stream:\n",
    "            try:\n",
    "                abm_params = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(\"Error in reading parameters file\")\n",
    "                print(exc)\n",
    "        params.update(abm_params)\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.num_agents = self.params[\"num_agents\"]  # Population\n",
    "\n",
    "\n",
    "class SEIRM(ODE):\n",
    "    def __init__(self, params, device):\n",
    "        super().__init__(params, device)\n",
    "\n",
    "    def init_compartments(self, learnable_params):\n",
    "        \"\"\"let's get initial conditions\"\"\"\n",
    "        initial_infections_percentage = learnable_params[\n",
    "            \"initial_infections_percentage\"\n",
    "        ]\n",
    "        initial_conditions = jnp.empty((5))\n",
    "        no_infected = (\n",
    "            initial_infections_percentage / 100\n",
    "        ) * self.num_agents  # 1.0 is ILI\n",
    "        initial_conditions = initial_conditions.at[2].set(no_infected)\n",
    "        initial_conditions = initial_conditions.at[0].set( self.num_agents - no_infected)\n",
    "        print(\"initial infected\", no_infected)\n",
    "        self.state = initial_conditions\n",
    "\n",
    "    def step(self, t, values):\n",
    "        \"\"\"\n",
    "        Computes ODE states via equations\n",
    "            state is the array of state value (S,E,I,R,M)\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"beta\": values[0],\n",
    "            \"alpha\": values[1],\n",
    "            \"gamma\": values[2],\n",
    "            \"mu\": values[3],\n",
    "            \"initial_infections_percentage\": values[4],\n",
    "        }\n",
    "        if t == 0:\n",
    "            self.init_compartments(params)\n",
    "        # to make the NN predict lower numbers, we can make its prediction to be N-Susceptible\n",
    "        dSE = params[\"beta\"] * self.state[0] * self.state[2] / self.num_agents\n",
    "        dEI = params[\"alpha\"] * self.state[1]\n",
    "        dIR = params[\"gamma\"] * self.state[2]\n",
    "        dIM = params[\"mu\"] * self.state[2]\n",
    "\n",
    "        dS = -1.0 * dSE\n",
    "        dE = dSE - dEI\n",
    "        dI = dEI - dIR - dIM\n",
    "        dR = dIR\n",
    "        dM = dIM\n",
    "\n",
    "        # concat and reshape to make it rows as obs, cols as states\n",
    "        self.dstate = jnp.stack([dS, dE, dI, dR, dM], 0)\n",
    "        NEW_INFECTIONS_TODAY = dEI\n",
    "        NEW_DEATHS_TODAY = dIM\n",
    "        # update state\n",
    "        self.state = self.state + self.dstate\n",
    "\n",
    "        return NEW_INFECTIONS_TODAY, NEW_DEATHS_TODAY\n",
    "\n",
    "class SIRS(ODE):\n",
    "    def __init__(self, params, device):\n",
    "        super().__init__(params, device)\n",
    "\n",
    "    def init_compartments(self, learnable_params):\n",
    "        \"\"\"let's get initial conditions\"\"\"\n",
    "        initial_infections_percentage = learnable_params[\n",
    "            \"initial_infections_percentage\"\n",
    "        ]\n",
    "        initial_conditions = jnp.empty((2))\n",
    "        no_infected = (\n",
    "            initial_infections_percentage / 100\n",
    "        ) * self.num_agents  # 1.0 is ILI\n",
    "        initial_conditions = initial_conditions.at[1].set(no_infected)\n",
    "        initial_conditions = initial_conditions.at[0].set(self.num_agents - no_infected)\n",
    "        print(\"initial infected\", no_infected)\n",
    "\n",
    "        self.state = initial_conditions\n",
    "\n",
    "    def step(self, t, values):\n",
    "        \"\"\"\n",
    "        Computes ODE states via equations\n",
    "            state is the array of state value (S,I)\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"beta\": values[0],  # contact rate, range: 0-1\n",
    "            \"initial_infections_percentage\": values[1],\n",
    "        }\n",
    "        # set from expertise\n",
    "        params[\"D\"] = 3.5\n",
    "        params[\"L\"] = 2000\n",
    "        if t == 0:\n",
    "            self.init_compartments(params)\n",
    "        dS = (self.num_agents - self.state[0] - self.state[1]) / params[\"L\"] - params[\n",
    "            \"beta\"\n",
    "        ] * self.state[0] * self.state[1] / self.num_agents\n",
    "        dSI = params[\"beta\"] * self.state[0] * self.state[1] / self.num_agents\n",
    "        dI = dSI - self.state[1] / params[\"D\"]\n",
    "\n",
    "        # concat and reshape to make it rows as obs, cols as states\n",
    "        self.dstate = jnp.stack([dS, dI], 0)\n",
    "\n",
    "        NEW_INFECTIONS_TODAY = dSI\n",
    "        # ILI is percentage of outpatients with influenza-like illness\n",
    "        # ILI = params['lambda'] * dSI / self.num_agents\n",
    "        ILI = dSI / self.num_agents * 100  # multiply 100 because it is percentage\n",
    "\n",
    "        # update state\n",
    "        self.state = self.state + self.dstate\n",
    "        return NEW_INFECTIONS_TODAY, ILI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random, lax\n",
    "import flax.linen as nn\n",
    "\n",
    "class LogitRelaxedBernoulli(nn.Module):\n",
    "    temperature: float = 0.3\n",
    "\n",
    "    def setup(self):\n",
    "        self.temperature = self.param(\"temperature\", nn.initializers.constant(self.temperature))\n",
    "\n",
    "    def rsample(self, rng_key, shape):\n",
    "        eps = random.uniform(rng_key, shape, minval=1e-6, maxval=1 - 1e-6)\n",
    "        logits = self.logits\n",
    "        y = (logits + jnp.log(eps) - jnp.log(1.0 - eps)) / self.temperature\n",
    "        return y\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        return (\n",
    "            jnp.log(self.temperature)\n",
    "            - self.temperature * value\n",
    "            + self.logits\n",
    "            - 2 * nn.softplus(-self.temperature * value + self.logits)\n",
    "        )\n",
    "\n",
    "class InfectionNetwork(nn.MessagePassing):\n",
    "    lam: nn.Module\n",
    "    R: nn.Module\n",
    "    SFSusceptibility: jnp.ndarray\n",
    "    SFInfector: jnp.ndarray\n",
    "    lam_gamma_integrals: jnp.ndarray\n",
    "\n",
    "    def setup(self, lam,R,SFSusceptibility,SFInfector,lam_gamma_integrals):\n",
    "        self.lam = lam\n",
    "        self.R = R\n",
    "        self.SFSusceptibility = SFSusceptibility\n",
    "        self.SFInfector = SFInfector\n",
    "        self.lam_gamma_integrals = lam_gamma_integrals\n",
    "\n",
    "    def forward_sparse(self, data, r0_value_trainable):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        t = data.t\n",
    "        # sparse adjacency matrix of inter-agent interactions\n",
    "        S_A_s = self.SFSusceptibility[x[:, 0].astype(jnp.int32)]\n",
    "        A_s_i = self.SFInfector[x[:, 1].astype(jnp.int32)]\n",
    "        integrals = jnp.zeros_like(S_A_s)\n",
    "        infected_idx = x[:, 2].astype(jnp.bool_)\n",
    "        infected_times = t - x[infected_idx, 3]\n",
    "        integrals = integrals.at[infected_idx].set(self.lam_gamma_integrals[infected_times.astype(jnp.int32)],)\n",
    "        I_bar = x[:, 4 + 22]  # only info for random network being used in current expts\n",
    "        integral_asi = A_s_i * integrals\n",
    "        sparse_adj = jax.scipy.sparse.coo_matrix(\n",
    "            (jnp.ones(edge_index.shape[1]), edge_index),\n",
    "            shape=(x.shape[0], x.shape[0])\n",
    "        ).tocsr()\n",
    "        sparse_asi = jax.scipy.sparse.coo_matrix(\n",
    "            (integral_asi.reshape(-1), (edge_index[0], edge_index[1])),\n",
    "            shape=(x.shape[0], 1)\n",
    "        ).tocsr()\n",
    "        sparse_mult = sparse_adj @ sparse_asi\n",
    "        dense_mult = sparse_mult.toarray().reshape(-1)\n",
    "\n",
    "        # total infection\n",
    "        infection_transmission = (\n",
    "            r0_value_trainable * S_A_s * dense_mult\n",
    "        ) / I_bar  # /I_bar\n",
    "        return infection_transmission.reshape(1, -1)\n",
    "\n",
    "    def forward(self, data, r0_value_trainable):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        t = data.t\n",
    "        return self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            edge_attr=edge_attr,\n",
    "            t=t,\n",
    "            R=r0_value_trainable,\n",
    "            SFSusceptibility=self.SFSusceptibility,\n",
    "            SFInfector=self.SFInfector,\n",
    "            lam_gamma_integrals=self.lam_gamma_integrals,\n",
    "        )\n",
    "\n",
    "    def message(\n",
    "        self,\n",
    "        x_i,\n",
    "        x_j,\n",
    "        edge_attr,\n",
    "        t,\n",
    "        R,\n",
    "        SFSusceptibility,\n",
    "        SFInfector,\n",
    "        lam_gamma_integrals,\n",
    "    ):\n",
    "        # x_j has shape [E, in_channels]\n",
    "        tmp = self.lam(\n",
    "            x_i, x_j, edge_attr, t, R, SFSusceptibility, SFInfector, lam_gamma_integrals\n",
    "        )  # tmp has shape [E, 2 * in_channels]\n",
    "        return tmp\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class DiseaseProgression(ABC, nn.Module):\n",
    "    \"\"\"Abstract class for disease progression\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def initialize_variables(self, agents_infected_time, agents_stages, agents_next_stage_times):\n",
    "        \"\"\"Initialize tensor variables depending on the disease\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_next_stage_times(self, learnable_params, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        \"\"\"Update the time for the next stage\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_current_stage(self, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        \"\"\"Update the current disease stage\"\"\"\n",
    "        pass\n",
    "\n",
    "class SEIRMProgression(DiseaseProgression):\n",
    "    \"\"\"SEIRM for COVID-19\"\"\"\n",
    "\n",
    "    SUSCEPTIBLE_VAR = 0\n",
    "    EXPOSED_VAR = 1  # exposed state\n",
    "    INFECTED_VAR = 2\n",
    "    RECOVERED_VAR = 3\n",
    "    MORTALITY_VAR = 4\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        # Default times (only for initialization, later they are learned)\n",
    "        self.EXPOSED_TO_INFECTED_TIME = 3\n",
    "        self.INFECTED_TO_RECOVERED_TIME = 5\n",
    "        self.INFINITY_TIME = params[\"num_steps\"] + 1\n",
    "        self.num_agents = params[\"num_agents\"]\n",
    "\n",
    "    def initialize_variables(self, agents_infected_time, agents_stages, agents_next_stage_times):\n",
    "        \"\"\"Initialize tensor variables depending on the disease\"\"\"\n",
    "        agents_infected_time = jax.ops.index_update(\n",
    "            agents_infected_time,\n",
    "            jax.numpy.logical_or(agents_stages == self.EXPOSED_VAR, agents_stages == self.INFECTED_VAR),\n",
    "            -1\n",
    "        )\n",
    "        agents_next_stage_times = jax.ops.index_update(\n",
    "            agents_next_stage_times,\n",
    "            agents_stages == self.EXPOSED_VAR,\n",
    "            self.EXPOSED_TO_INFECTED_TIME\n",
    "        )\n",
    "        agents_next_stage_times = jax.ops.index_update(\n",
    "            agents_next_stage_times,\n",
    "            agents_stages == self.INFECTED_VAR,\n",
    "            -1 * self.EXPOSED_TO_INFECTED_TIME\n",
    "        )\n",
    "        return agents_infected_time, agents_next_stage_times\n",
    "\n",
    "    def update_next_stage_times(self, learnable_params, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        \"\"\"Update the time for the next stage\"\"\"\n",
    "        exposed_to_infected_time = learnable_params[\"exposed_to_infected_time\"]\n",
    "        infected_to_recovered_time = learnable_params[\"infected_to_recovered_time\"]\n",
    "        new_transition_times = agents_next_stage_times.copy()\n",
    "        new_transition_times = jax.ops.index_update(\n",
    "            new_transition_times,\n",
    "            jnp.logical_and(current_stages == self.INFECTED_VAR, agents_next_stage_times == t),\n",
    "            self.INFINITY_TIME\n",
    "        )\n",
    "        new_transition_times = jax.ops.index_update(\n",
    "            new_transition_times,\n",
    "            jnp.logical_and(current_stages == self.EXPOSED_VAR, agents_next_stage_times == t),\n",
    "            t + infected_to_recovered_time\n",
    "        )\n",
    "        return jnp.where(\n",
    "            newly_exposed_today,\n",
    "            (t + 1 + exposed_to_infected_time),\n",
    "            new_transition_times\n",
    "        )\n",
    "\n",
    "    def update_current_stage(self, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        \"\"\"Update the current disease stage\"\"\"\n",
    "        transition_to_infected = jnp.where(agents_next_stage_times <= t, self.INFECTED_VAR, self.EXPOSED_VAR)\n",
    "        transition_to_mortality_or_recovered = jnp.where(agents_next_stage_times <= t, self.RECOVERED_VAR, self.INFECTED_VAR)\n",
    "        stage_progression = jnp.where(\n",
    "            current_stages == self.SUSCEPTIBLE_VAR,\n",
    "            self.SUSCEPTIBLE_VAR,\n",
    "            jnp.where(\n",
    "                current_stages == self.RECOVERED_VAR,\n",
    "                self.RECOVERED_VAR,\n",
    "                jnp.where(\n",
    "                    current_stages == self.MORTALITY_VAR,\n",
    "                    self.MORTALITY_VAR,\n",
    "                    jnp.where(\n",
    "                        current_stages == self.EXPOSED_VAR,\n",
    "                        transition_to_infected,\n",
    "                        transition_to_mortality_or_recovered\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        current_stages = jnp.where(\n",
    "            newly_exposed_today,\n",
    "            self.EXPOSED_VAR,\n",
    "            stage_progression\n",
    "        )\n",
    "        return current_stages\n",
    "\n",
    "    def init_stages(self, learnable_params, device):\n",
    "        \"\"\"Initialize the stages\"\"\"\n",
    "        initial_infections_percentage = learnable_params[\"initial_infections_percentage\"]\n",
    "        prob_infected = (initial_infections_percentage / 100) * jnp.ones((self.num_agents, 1), dtype=jnp.float32)\n",
    "        p = jnp.concatenate((prob_infected, 1 - prob_infected), axis=1)\n",
    "        cat_logits = jnp.log(p + 1e-9)\n",
    "        agents_stages = jax.nn.gumbel_softmax(cat_logits, tau=1, hard=True, axis=1)[:, 0]\n",
    "        return agents_stages\n",
    "\n",
    "class SIRSProgression(DiseaseProgression):\n",
    "    \"\"\"SIRS for influenza\"\"\"\n",
    "\n",
    "    SUSCEPTIBLE_VAR = 0\n",
    "    INFECTED_VAR = 1\n",
    "    RECOVERED_VAR = 2\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        # Default times (only for initialization, later they are learned)\n",
    "        self.INFECTED_TO_RECOVERED_TIME = 5\n",
    "        self.RECOVERED_TO_SUSCEPTIBLE_TIME = 100\n",
    "        self.INFINITY_TIME = params[\"num_steps\"] + 1\n",
    "        self.num_agents = params[\"num_agents\"]\n",
    "\n",
    "    def initialize_variables(self, agents_infected_time, agents_stages, agents_next_stage_times):\n",
    "        \"\"\"Initialize tensor variables depending on the disease\"\"\"\n",
    "        agents_infected_time = jax.ops.index_update(\n",
    "            agents_infected_time,\n",
    "            agents_stages == self.INFECTED_VAR,\n",
    "            -1\n",
    "        )\n",
    "        agents_next_stage_times = jax.ops.index_update(\n",
    "            agents_next_stage_times,\n",
    "            agents_stages == self.INFECTED_VAR,\n",
    "            self.INFECTED_TO_RECOVERED_TIME\n",
    "        )\n",
    "        return agents_infected_time, agents_next_stage_times\n",
    "\n",
    "    def update_initial_times(self, learnable_params, agents_stages, agents_next_stage_times):\n",
    "        infected_to_recovered_time = learnable_params[\"infected_to_recovered_time\"]\n",
    "        new_transition_times = jax.ops.index_update(\n",
    "            agents_next_stage_times,\n",
    "            jnp.logical_and(agents_stages == self.INFECTED_VAR, agents_next_stage_times <= t),\n",
    "            infected_to_recovered_time\n",
    "        )\n",
    "        return new_transition_times\n",
    "\n",
    "    def get_newly_exposed(self, current_stages, potentially_exposed_today):\n",
    "        newly_exposed_today = jnp.logical_and(current_stages == self.SUSCEPTIBLE_VAR, potentially_exposed_today)\n",
    "        return newly_exposed_today\n",
    "\n",
    "    def update_next_stage_times(self, learnable_params, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        infected_to_recovered_time = learnable_params[\"infected_to_recovered_time\"]\n",
    "        recovered_to_susceptible_time = learnable_params[\"recovered_to_susceptible_time\"]\n",
    "        new_transition_times = jnp.where(\n",
    "            jnp.logical_and(current_stages == self.INFECTED_VAR, agents_next_stage_times == t),\n",
    "            (t + recovered_to_susceptible_time),\n",
    "            agents_next_stage_times\n",
    "        )\n",
    "        return jnp.where(\n",
    "            newly_exposed_today,\n",
    "            (t + 1 + infected_to_recovered_time),\n",
    "            new_transition_times\n",
    "        )\n",
    "\n",
    "    def get_target_variables(self, params, learnable_params, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        new_recovered_today = jnp.where(\n",
    "            jnp.logical_and(current_stages == self.INFECTED_VAR, agents_next_stage_times <= t),\n",
    "            self.RECOVERED_VAR,\n",
    "            self.INFECTED_VAR\n",
    "        )\n",
    "        ILI = jnp.sum(newly_exposed_today) / params[\"num_agents\"] * 100\n",
    "        NEW_INFECTIONS_TODAY = jnp.sum(newly_exposed_today)\n",
    "        return new_recovered_today, NEW_INFECTIONS_TODAY, ILI\n",
    "\n",
    "    def update_current_stage(self, newly_exposed_today, current_stages, agents_next_stage_times, t):\n",
    "        transition_to_recovered = jnp.where(agents_next_stage_times <= t, self.RECOVERED_VAR, self.INFECTED_VAR)\n",
    "        transition_to_susceptible = jnp.where(agents_next_stage_times <= t, self.SUSCEPTIBLE_VAR, self.RECOVERED_VAR)\n",
    "        stage_progression = jnp.where(\n",
    "            newly_exposed_today,\n",
    "            self.INFECTED_VAR,\n",
    "            jnp.where(\n",
    "                current_stages == self.SUSCEPTIBLE_VAR,\n",
    "                self.SUSCEPTIBLE_VAR,\n",
    "                jnp.where(\n",
    "                    current_stages == self.RECOVERED_VAR,\n",
    "                    self.RECOVERED_VAR,\n",
    "                    jnp.where(\n",
    "                        current_stages == self.INFECTED_VAR,\n",
    "                        transition_to_recovered,\n",
    "                        transition_to_susceptible\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        current_stages = jnp.where(\n",
    "            newly_exposed_today,\n",
    "            self.INFECTED_VAR,\n",
    "            stage_progression\n",
    "        )\n",
    "        return current_stages\n",
    "\n",
    "    def init_stages(self, learnable_params, device):\n",
    "        initial_infections_percentage = learnable_params[\"initial_infections_percentage\"]\n",
    "        prob_infected = (initial_infections_percentage / 100) * jnp.ones((self.num_agents, 1), dtype=jnp.float32)\n",
    "        p = jnp.concatenate((prob_infected, 1 - prob_infected), axis=1)\n",
    "        cat_logits = jnp.log(p + 1e-9)\n",
    "        agents_stages = jax.nn.gumbel_softmax(cat_logits, tau=1, hard=True, axis=1)[:, 0]\n",
    "        return agents_stages\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax import linen as nn\n",
    "from scipy.stats import gamma\n",
    "from functools import partial\n",
    "\n",
    "class GradABM:\n",
    "    def __init__(self, params, device):\n",
    "        county_id = params[\"county_id\"]\n",
    "        abm_params = f\"/kaggle/input/gradabmdata/Data/ABM_parameters/{county_id}_generated_params.yaml\"\n",
    "\n",
    "        # Reading params\n",
    "        with open(abm_params, \"r\") as stream:\n",
    "            try:\n",
    "                abm_params = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(\"Error in reading parameters file\")\n",
    "                print(exc)\n",
    "    \n",
    "        params.update(abm_params)\n",
    "        params[\"output_location\"][\"parent_dir\"] = \"/kaggle/input/gradabmdata/Data\"\n",
    "        self.params = params\n",
    "        self.device = device\n",
    "        self.num_agents = self.params[\"num_agents\"]\n",
    "        print(\"Num Agents: \", self.num_agents)\n",
    "\n",
    "        # **********************************************************************************\n",
    "        # Environment state variables\n",
    "        # **********************************************************************************\n",
    "        # **********************************************************************************\n",
    "        # Static\n",
    "        self.agents_ix = jnp.arange(0, self.params[\"num_agents\"])\n",
    "        infile = os.path.join(\n",
    "            self.params[\"output_location\"][\"parent_dir\"],\n",
    "            self.params[\"output_location\"][\"agents_dir\"],\n",
    "            self.params[\"output_location\"][\"agents_outfile\"],\n",
    "        )\n",
    "\n",
    "        agents_df = pd.read_csv(infile)\n",
    "        self.agents_ages = jnp.array(agents_df[\"age_group\"].to_numpy())\n",
    "\n",
    "        self.num_networks = 23\n",
    "        self.network_type_dict = {}\n",
    "        self.network_type_dict[\"random\"] = 22\n",
    "        self.network_type_dict_inv = {}\n",
    "        self.network_type_dict_inv[22] = \"random\"\n",
    "        \n",
    "        params['disease'] = \"COVID\"\n",
    "        # select disease progression model\n",
    "        if params['disease'] == \"COVID\":\n",
    "            self.DPM = SEIRMProgression(params)\n",
    "        elif params['disease'] == \"Flu\":\n",
    "            self.DPM = SIRSProgression(params)\n",
    "\n",
    "        # Age and Network and Occupation may need to be checked to populate this\n",
    "        self.agents_mean_interactions = jnp.zeros(\n",
    "            (self.params[\"num_agents\"], self.num_networks)\n",
    "        )\n",
    "\n",
    "        mean_int_ran_df = pd.read_csv(\"/kaggle/input/gradabmdata/Data/Initialization/RandomNetworkParameters.csv\")\n",
    "        mean_int_ran_mu = jnp.array(mean_int_ran_df[\"mu\"].values)\n",
    "\n",
    "        child_agents = self.agents_ages <= self.params[\"CHILD_Upper_Index\"]\n",
    "        adult_agents = jnp.logical_and(\n",
    "            self.agents_ages > self.params[\"CHILD_Upper_Index\"],\n",
    "            self.agents_ages <= self.params[\"ADULT_Upper_Index\"],\n",
    "        ).reshape(-1)\n",
    "        elderly_agents = self.agents_ages > self.params[\"ADULT_Upper_Index\"]\n",
    "        self.agents_mean_interactions = jax.ops.index_update(\n",
    "            self.agents_mean_interactions, jax.ops.index[child_agents, 22], mean_int_ran_mu[0]\n",
    "        )\n",
    "        self.agents_mean_interactions = jax.ops.index_update(\n",
    "            self.agents_mean_interactions, jax.ops.index[adult_agents, 22], mean_int_ran_mu[1]\n",
    "        )\n",
    "        self.agents_mean_interactions = jax.ops.index_update(\n",
    "            self.agents_mean_interactions, jax.ops.index[elderly_agents, 22], mean_int_ran_mu[2]\n",
    "        )\n",
    "        self.agents_mean_interactions_split = [\n",
    "            a.reshape(-1) for a in jnp.split(self.agents_mean_interactions, 1, axis=1)\n",
    "        ]\n",
    "\n",
    "        self.R = 5.18  # learnable, but the default value\n",
    "        self.R = jnp.array(self.R)\n",
    "        if self.params['disease'] == \"COVID\":\n",
    "            self.SFSusceptibility = jnp.array([0.35, 0.69, 1.03, 1.03, 1.03, 1.03, 1.27, 1.52, 1.52], dtype=jnp.float32)\n",
    "            self.SFInfector = jnp.array([0.0, 0.33, 0.72, 0.0, 0.0], dtype=jnp.float32)\n",
    "            self.lam_gamma = {}\n",
    "            self.lam_gamma[\"scale\"] = 5.5\n",
    "            self.lam_gamma[\"rate\"] = 2.14\n",
    "        elif self.params['disease'] == \"Flu\":\n",
    "            # from CDC Table 1, median value: https://www.cdc.gov/flu/about/keyfacts.htm\n",
    "            self.SFSusceptibility = jnp.array([13.2, 7.9, 7.4, 7.4, 7.4, 12.0, 12.0, 3.9, 3.9], dtype=jnp.float32)\n",
    "            self.SFSusceptibility = nn.softmax(self.SFSusceptibility, axis=0) * 25\n",
    "            self.SFInfector = jnp.array([0.0, 0.72, 0.0], dtype=jnp.float32)\n",
    "            self.lam_gamma = {}\n",
    "            self.lam_gamma[\"scale\"] = 7.5  # mean is scale/rate, CDC says it's 3-4 days\n",
    "            self.lam_gamma[\"rate\"] = 2.14\n",
    "\n",
    "        self.B_n = {}\n",
    "        self.B_n[\"household\"] = 2\n",
    "        self.B_n[\"occupation\"] = 1\n",
    "        self.B_n[\"random\"] = 1  # 0.25\n",
    "\n",
    "        self.lam_gamma_integrals = self._get_lam_gamma_integrals(\n",
    "            **self.lam_gamma, t=self.params[\"num_steps\"] + 10\n",
    "        )  # add 10 to make sure we cover all\n",
    "        self.lam_gamma_integrals = self.lam_gamma_integrals\n",
    "\n",
    "        self.net = InfectionNetwork(\n",
    "            lam,\n",
    "            self.R,\n",
    "            self.SFSusceptibility,\n",
    "            self.SFInfector,\n",
    "            self.lam_gamma_integrals,\n",
    "            self.device,\n",
    "        )\n",
    "\n",
    "        self.current_time = 0\n",
    "        # **********************************************************************************\n",
    "        self.all_edgelist, self.all_edgeattr = self.init_interaction_graph(\n",
    "            t=0\n",
    "        )  # get one initial interaction graph\n",
    "\n",
    "    def init_interaction_graph(self, t):\n",
    "        \"\"\"this is Part-1 of Step\"\"\"\n",
    "        \n",
    "        infile = os.path.join(\n",
    "            get_dir_from_path_list(\n",
    "                [\n",
    "                    self.params[\"output_location\"][\"parent_dir\"],\n",
    "                    self.params[\"output_location\"][\"networks_dir\"],\n",
    "                    self.params[\"output_location\"][\"random_networks_dir\"],\n",
    "                ]\n",
    "            ),\n",
    "            \"{}.csv\".format(t),\n",
    "        )\n",
    "\n",
    "        random_network_edgelist_forward = jnp.array(pd.read_csv(infile, header=None).to_numpy().T, dtype=jnp.int32)\n",
    "        random_network_edgelist_backward = jnp.vstack(\n",
    "            (\n",
    "                random_network_edgelist_forward[1, :],\n",
    "                random_network_edgelist_forward[0, :],\n",
    "            )\n",
    "        )\n",
    "        random_network_edgelist = jnp.hstack(\n",
    "            (random_network_edgelist_forward, random_network_edgelist_backward)\n",
    "        )\n",
    "        random_network_edgeattr_type = jnp.ones(random_network_edgelist.shape[1], dtype=jnp.int32) * self.network_type_dict[\"random\"]\n",
    "\n",
    "        random_network_edgeattr_B_n = jnp.ones(random_network_edgelist.shape[1], dtype=jnp.float32) * self.B_n[\"random\"]\n",
    "        random_network_edgeattr = jnp.vstack(\n",
    "            (random_network_edgeattr_type, random_network_edgeattr_B_n)\n",
    "        )\n",
    "\n",
    "        all_edgelist = jnp.hstack((random_network_edgelist,))\n",
    "        all_edgeattr = jnp.hstack((random_network_edgeattr,))\n",
    "\n",
    "        return all_edgelist, all_edgeattr\n",
    "\n",
    "    def get_interaction_graph(self, t):\n",
    "        return self.all_edgelist, self.all_edgeattr\n",
    "\n",
    "    def init_state_tensors(self, learnable_params):\n",
    "        \"\"\"Initializing message passing network (currently no trainable parameters here)\"\"\"\n",
    "        # Dynamic\n",
    "        # a.Testing\n",
    "        # b.Quarantine\n",
    "        # c.Infection and Disease\n",
    "        self.current_stages = self.DPM.init_stages(learnable_params, self.device)\n",
    "        self.agents_infected_index = (self.current_stages > 0).astype(jnp.float32)  # Not susceptible\n",
    "        self.agents_infected_time = (\n",
    "            (self.params[\"num_steps\"] + 1) * jnp.ones_like(self.current_stages)\n",
    "        ).astype(jnp.float32)  # Practically infinite as np.inf gives wrong data type\n",
    "\n",
    "        self.agents_next_stages = -1 * jnp.ones_like(self.current_stages)\n",
    "        self.agents_next_stage_times = (self.params[\"num_steps\"] + 1) * jnp.ones_like(\n",
    "            self.current_stages\n",
    "        ).astype(jnp.int32)  # Practically infinite as np.inf gives wrong data type\n",
    "\n",
    "        # update values depending on the disease\n",
    "        (\n",
    "            self.agents_infected_time,\n",
    "            self.agents_next_stage_times,\n",
    "        ) = self.DPM.initialize_variables(\n",
    "            self.agents_infected_time, self.current_stages, self.agents_next_stage_times\n",
    "        )\n",
    "\n",
    "        self.agents_next_stage_times = self.agents_next_stage_times.astype(jnp.float32)\n",
    "        self.agents_infected_time = self.agents_infected_time.astype(jnp.float32)\n",
    "\n",
    "    def step(self, t, param_t):\n",
    "        \"\"\"Send as input: r0_value [hidden state] -> trainable parameters  and t is the time-step of simulation.\"\"\"\n",
    "        # construct dictionary with trainable parameters\n",
    "        learnable_params = {}\n",
    "        if self.params['disease'] == \"COVID\":\n",
    "            learnable_params[\"r0_value\"] = param_t[0]\n",
    "            learnable_params[\"mortality_rate\"] = param_t[1]\n",
    "            learnable_params[\"initial_infections_percentage\"] = param_t[2]\n",
    "            learnable_params[\"exposed_to_infected_time\"] = 3\n",
    "            learnable_params[\"infected_to_recovered_time\"] = 5\n",
    "        elif self.params['disease'] == \"Flu\":\n",
    "            learnable_params[\"r0_value\"] = param_t[0]\n",
    "            learnable_params[\"initial_infections_percentage\"] = param_t[1]\n",
    "            learnable_params[\"infected_to_recovered_time\"] = 3.5\n",
    "            learnable_params[\"recovered_to_susceptible_time\"] = 2000\n",
    "        \"\"\" change params that were set in constructor \"\"\"\n",
    "        if t == 0:\n",
    "            self.init_state_tensors(learnable_params)\n",
    "            self.agents_next_stage_times = self.DPM.update_initial_times(\n",
    "                learnable_params, self.current_stages, self.agents_next_stage_times\n",
    "            )\n",
    "\n",
    "        # t = self.current_time\n",
    "        \"\"\"Steps: i) Get interaction graph, ii) Message Passing of Infection iii) State Evolution \"\"\"\n",
    "\n",
    "        # ******************************************************************************** #\n",
    "        # Part-1. Interaction Graph - Output: EdgeList, EdgeFeatures and NodeFeatures\n",
    "        all_edgelist, all_edgeattr = self.get_interaction_graph(\n",
    "            t\n",
    "        )  # the interaction graphs for GNN at time t\n",
    "        all_nodeattr = jnp.stack(\n",
    "            (\n",
    "                self.agents_ages,  # 0\n",
    "                self.current_stages.detach(),  # 1\n",
    "                self.agents_infected_index.to(self.device),  # 2\n",
    "                self.agents_infected_time.to(self.device),  # 3\n",
    "                *self.agents_mean_interactions_split,  # 4 to 26\n",
    "                jnp.arange(self.params[\"num_agents\"]).to(\n",
    "                    self.device\n",
    "                ),  # Agent ids (27)\n",
    "            )\n",
    "        ).T\n",
    "        agents_data = Data(\n",
    "            all_nodeattr,\n",
    "            edge_index=all_edgelist,\n",
    "            edge_attr=all_edgeattr,\n",
    "            t=t,\n",
    "            agents_mean_interactions=self.agents_mean_interactions,\n",
    "        )\n",
    "\n",
    "        # ******************************************************************************** #\n",
    "        # Part-2. Message Passing - Transmission Dynamics + New Infections: {GNN + Variational Inference}\n",
    "        # agent steps: i) collects infection [GNN]; ii) get infected based on total infection collected [Variational Inference]\n",
    "        # message passing: collecting infection from neighbors\n",
    "        lam_t = self.net(agents_data, learnable_params[\"r0_value\"])\n",
    "        prob_not_infected = jnp.exp(-lam_t)\n",
    "        p = jnp.hstack((1 - prob_not_infected, prob_not_infected))\n",
    "        cat_logits = jnp.log(p + 1e-9)\n",
    "        potentially_exposed_today = nn.gumbel_softmax(\n",
    "            logits=cat_logits, tau=1, hard=True, axis=1\n",
    "        )[\n",
    "            :, 0\n",
    "        ]  # first column is prob of infections\n",
    "        newly_exposed_today = self.DPM.get_newly_exposed(\n",
    "            self.current_stages, potentially_exposed_today\n",
    "        )\n",
    "\n",
    "        # ******************************************************************************** #\n",
    "        # Part-3. State Evolution -> Progression Dynamics {Deterministic}\n",
    "        # to do here: i) update curr_stage; ii) update next_transition_time\n",
    "        # self.agents_infected_time[t].sum()\n",
    "        # check 2 things: i) got infected_today -> go from S to E; ii) already infected -> update E to I; I to R or M.\n",
    "        # stage_progression, new_death_recovered_today = self.deterministic_stage_transition(self.agents_stages[t,:],\n",
    "\n",
    "        # before updating, get target variables like new deaths or ILI\n",
    "        # also get recovered ones\n",
    "        recovered_dead_now, target1, target2 = self.DPM.get_target_variables(\n",
    "            self.params,\n",
    "            learnable_params,\n",
    "            newly_exposed_today,\n",
    "            self.current_stages,\n",
    "            self.agents_next_stage_times,\n",
    "            t,\n",
    "        )\n",
    "\n",
    "        # get next stages without updating yet the current_stages\n",
    "        next_stages = self.DPM.update_current_stage(\n",
    "            newly_exposed_today, self.current_stages, self.agents_next_stage_times, t\n",
    "        )\n",
    "\n",
    "        # update times with current_stages\n",
    "        self.agents_next_stage_times = self.DPM.update_next_stage_times(\n",
    "            learnable_params,\n",
    "            newly_exposed_today,\n",
    "            self.current_stages,\n",
    "            self.agents_next_stage_times,\n",
    "            t,\n",
    "        )\n",
    "\n",
    "        # safely update current_stages\n",
    "        self.current_stages = next_stages\n",
    "\n",
    "        # update for newly exposed agents {exposed_today}\n",
    "        self.agents_infected_index = jax.ops.index_update(self.agents_infected_index, newly_exposed_today.astype(jnp.bool_), 1)\n",
    "        self.agents_infected_time = jax.ops.index_update(self.agents_infected_time, newly_exposed_today.astype(jnp.bool_), t)\n",
    "        self.current_time = t + 1\n",
    "\n",
    "        # ******************************************************************************** #\n",
    "        # TODO: Part-4. ILI/ILI-probability update for next step -> on newly_exposed_today and current_stages\n",
    "        # self.AILI_model.updateILI(current_stages.detach(), self.agents_mean_interactions, t)\n",
    "\n",
    "        # ******************************************************************************** #\n",
    "        # Wrap it all together\n",
    "        wrapped_output = [recovered_dead_now, target1, target2]\n",
    "        wrapped_output = [x for x in wrapped_output if x is not None]\n",
    "        wrapped_output = (\n",
    "            tuple(wrapped_output) if len(wrapped_output) > 1 else wrapped_output[0]\n",
    "        )\n",
    "\n",
    "        return wrapped_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # foward will be used for training and testing purposes\n",
    "        output = []\n",
    "        for i in range(self.params[\"num_steps\"]):\n",
    "            # inference time\n",
    "            if len(x) > 0:\n",
    "                output.append(self.step(i, x[i]))\n",
    "            else:\n",
    "                output.append(self.step(i, []))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def process_output(self, output):\n",
    "        # process the output to return meaningful data\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_abm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_TRAIN = False\n",
    "NUM_EPOCHS_DIFF = 15\n",
    "print(\"---- MAIN IMPORTS SUCCESSFUL -----\")\n",
    "epsilon = 1e-6\n",
    "\n",
    "MIN_VAL_PARAMS = {\n",
    "\"abm-covid\": [\n",
    "1.0,\n",
    "0.001,\n",
    "0.01,\n",
    "], # r0, mortality rate, initial_infections_percentage\n",
    "\"abm-flu\": [1.05, 0.1], # r0, initial_infections_percentage\n",
    "\"seirm\": [\n",
    "0.0,\n",
    "0.0,\n",
    "0.0,\n",
    "0.0,\n",
    "0.01,\n",
    "], # beta, alpha, gamma, mu, initial_infections_percentage\n",
    "\"sirs\": [0.0, 0.1], # beta, initial_infections_percentage\n",
    "}\n",
    "MAX_VAL_PARAMS = {\n",
    "\"abm-covid\": [8.0, 0.02, 1.0],\n",
    "\"abm-flu\": [2.6, 5.0],\n",
    "\"seirm\": [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "\"sirs\": [1.0, 5.0],\n",
    "}\n",
    "\n",
    "DAYS_HEAD = 4 * 7 # 4 weeks ahead\n",
    "\n",
    "pi = jnp.array([math.pi], dtype=jnp.float32)\n",
    "\n",
    "SAVE_MODEL_PATH = \"/kaggle/working/Models/\"\n",
    "\n",
    "# neural network predicting parameters of the ABM\n",
    "class CalibNN(nn.Module):\n",
    "    def init(\n",
    "    self,\n",
    "    metas_train_dim,\n",
    "    X_train_dim,\n",
    "    device,\n",
    "    training_weeks,\n",
    "    hidden_dim=32,\n",
    "    out_dim=1,\n",
    "    n_layers=2,\n",
    "    scale_output=\"abm-covid\",\n",
    "    bidirectional=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.training_weeks = training_weeks\n",
    "\n",
    "        \"\"\" tune \"\"\"\n",
    "        hidden_dim = 64\n",
    "        out_layer_dim = 32\n",
    "\n",
    "        self.emb_model = EmbedAttenSeq(\n",
    "            dim_seq_in=X_train_dim,\n",
    "            dim_metadata=metas_train_dim,\n",
    "            rnn_out=hidden_dim,\n",
    "            dim_out=hidden_dim,\n",
    "            n_layers=n_layers, \n",
    "            dropout=0.1,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        self.decoder = DecodeSeq(\n",
    "            dim_seq_in=1,\n",
    "            rnn_out=hidden_dim,  # divides by 2 if bidirectional\n",
    "            dim_out=out_layer_dim,\n",
    "            n_layers=1,\n",
    "            dropout=0.1,\n",
    "            dim_metadata=metas_train_dim,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        out_layer_width = out_layer_dim\n",
    "        self.out_layer = [\n",
    "            nn.Linear(in_features=out_layer_width, out_features=out_layer_width // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=out_layer_width // 2, out_features=out_dim),\n",
    "        ]\n",
    "        self.out_layer = nn.Sequential(*self.out_layer)\n",
    "\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.initializers.xavier_uniform()(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.out_layer.apply(init_weights)\n",
    "        self.min_values = jnp.array(MIN_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.max_values = jnp.array(MAX_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x_embeds, encoder_hidden = self.emb_model.forward(x.transpose(1, 0), meta)\n",
    "        # create input that will tell the neural network which week it is predicting\n",
    "        # thus, we have one element in the sequence per each week of R0\n",
    "        time_seq = (\n",
    "            jnp.arange(1, self.training_weeks + WEEKS_AHEAD + 1)\n",
    "            .repeat(x_embeds.shape[0], 1)\n",
    "            .unsqueeze(2)\n",
    "        )\n",
    "        Hi_data = ((time_seq - time_seq.min()) / (time_seq.max() - time_seq.min())).to(\n",
    "            self.device\n",
    "        )\n",
    "        emb = self.decoder(Hi_data, encoder_hidden, x_embeds)\n",
    "        out = self.out_layer(emb)\n",
    "        out = self.min_values + (self.max_values - self.min_values) * self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "class ParamModel(nn.Module):\n",
    "    def init(\n",
    "    self,\n",
    "    metas_train_dim,\n",
    "    X_train_dim,\n",
    "    device,\n",
    "    hidden_dim=50,\n",
    "    n_layers=2,\n",
    "    out_dim=1,\n",
    "    scale_output=\"abm-covid\",\n",
    "    bidirectional=True,\n",
    "    CUSTOM_INIT=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.emb_model = EmbedAttenSeq(\n",
    "            dim_seq_in=X_train_dim,\n",
    "            dim_metadata=metas_train_dim,\n",
    "            dim_out=hidden_dim,\n",
    "            n_layers=n_layers,\n",
    "            dropout=0.1,\n",
    "            rnn_out=hidden_dim,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Linear(in_features=hidden_dim, out_features=20)\n",
    "        # used to bypass the RNN - we want to check what's happening with gradients\n",
    "        self.layer_bypass = nn.Linear(in_features=metas_train_dim, out_features=20)\n",
    "        self.meanfc = nn.Linear(in_features=20, out_features=out_dim, bias=True)\n",
    "        self.min_values = jnp.array(MIN_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.max_values = jnp.array(MAX_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        if CUSTOM_INIT:\n",
    "            self.meanfc.bias = nn.Parameter(jnp.array([1.0]))\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x_embeds = self.emb_model.forward(x.transpose(1, 0), meta)\n",
    "        # use embedding for predicting: i) R0 and ii) Cases {for support counties} [FOR LATER]\n",
    "        ro_feats = self.layer1(x_embeds)\n",
    "        ro_feats = nn.ReLU()(ro_feats)\n",
    "        out = self.meanfc(ro_feats)\n",
    "        # else:\n",
    "        \"\"\" bound output \"\"\"\n",
    "        out = self.min_values + (self.max_values - self.min_values) * self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class LearnableParams(nn.Module):\n",
    "    \"\"\"doesn't use data signals\"\"\"\n",
    "\n",
    "    def __init__(self, num_params, device, scale_output=\"abm-covid\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.learnable_params = nn.Parameter(jnp.rand(num_params, device=self.device))\n",
    "        self.min_values = jnp.array(MIN_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.max_values = jnp.array(MAX_VAL_PARAMS[scale_output], device=self.device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self):\n",
    "        out = self.learnable_params\n",
    "        \"\"\" bound output \"\"\"\n",
    "        out = self.min_values + (self.max_values - self.min_values) * self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "def normal(x, mu, sigma_sq):\n",
    "    a = (-1 * (jnp.asarray(x) - mu).pow(2) / (2 * sigma_sq)).exp()\n",
    "    b = 1 / (2 * sigma_sq * pi.expand_as(sigma_sq)).sqrt()\n",
    "    return a * b\n",
    "\n",
    "def save_model(model, file_name, disease, region, week):\n",
    "    PATH = os.path.join(SAVE_MODEL_PATH, disease, region)\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "    jnp.savez_compressed(PATH + \"/\" + file_name + \" \" + week + \".npz\", **model.params)\n",
    "\n",
    "def load_model(model, file_name, disease, region, week, device):\n",
    "    PATH = os.path.join(SAVE_MODEL_PATH, disease, region)\n",
    "    params = jnp.load(PATH + \"/\" + file_name + \" \" + week + \".npz\")\n",
    "    model.params = params\n",
    "    return model\n",
    "\n",
    "def param_model_forward(param_model, params, x, meta):\n",
    "    # get R0 from county network\n",
    "    if params[\"model_name\"].startswith(\"GradABM-time-varying\"):\n",
    "        action_value = param_model.forward(x, meta) # time-varying\n",
    "    elif params[\"model_name\"] == \"ABM-expert\":\n",
    "        if params['disease'] == \"COVID\":\n",
    "            action_value = jnp.array([2.5, 0.02, 0.5]) # from CDC, for COVID -- previous I0 was 0.01\n",
    "    if params['disease'] == \"Flu\":\n",
    "        action_value = jnp.array([1.3, 1.0]) # from CDC, for COVID\n",
    "        action_value = jnp.repeat(action_value, meta.shape[0], 0)\n",
    "    elif \"ABM-pred-correction\" in params[\"model_name\"]: # same as SEIRM-static, but get\n",
    "        action_value = param_model.forward()\n",
    "        if params['disease'] == \"COVID\":\n",
    "            # NOTE: to fix, beta/gamma is for SIR, maybe not the same for SEIRM\n",
    "            beta = action_value[0]\n",
    "            gamma = action_value[2]\n",
    "            mu = action_value[3] # mortality rate\n",
    "            initial_infections_percentage = action_value[4]\n",
    "            action_value = jnp.stack(\n",
    "            [beta / (gamma + mu), mu, initial_infections_percentage]\n",
    "            )\n",
    "        elif params['disease'] == \"Flu\":\n",
    "            beta = action_value[0]\n",
    "            # D = action_value[:,1]\n",
    "            D = 3.5\n",
    "            initial_infections_percentage = action_value[1]\n",
    "            action_value = jnp.stack([beta * D, initial_infections_percentage])\n",
    "            action_value = action_value.reshape(1, -1) # make sure it's 2d\n",
    "            print(\"R0 ABM-pred-correction\", action_value)\n",
    "    elif \"GradABM-learnable-params\" in params[\"model_name\"]:\n",
    "        action_value = param_model.forward()\n",
    "        action_value = jnp.repeat(action_value, meta.shape[0], 0)\n",
    "    else:\n",
    "        raise ValueError(\"model name not valid\")\n",
    "    return action_value\n",
    "\n",
    "def build_param_model(params, metas_train_dim, X_train_dim, device, CUSTOM_INIT=True):\n",
    "    # get param dimension for ODE\n",
    "    if params['disease'] == \"COVID\":\n",
    "        ode_param_dim = 5\n",
    "        abm_param_dim = 3\n",
    "        scale_output_ode = \"seirm\"\n",
    "        scale_output_abm = \"abm-covid\"\n",
    "    elif params['disease'] == \"Flu\":\n",
    "        ode_param_dim = 2\n",
    "        abm_param_dim = 2\n",
    "        scale_output_ode = \"sirs\"\n",
    "        scale_output_abm = \"abm-flu\"\n",
    "    training_weeks = params[\"num_steps\"] / 7  # only needed for time-varying\n",
    "    assert training_weeks == int(training_weeks)\n",
    "\n",
    "    \"\"\" call constructor of param model depending on the model we want to run\"\"\"\n",
    "    if params[\"model_name\"].startswith(\"GradABM-time-varying\"):\n",
    "        param_model = CalibNN(\n",
    "            metas_train_dim,\n",
    "            X_train_dim,\n",
    "            device,\n",
    "            training_weeks,\n",
    "            out_dim=abm_param_dim,\n",
    "            scale_output=scale_output_abm,\n",
    "        ).to(device)\n",
    "    elif params[\"model_name\"] == \"ABM-expert\":\n",
    "        param_model = None\n",
    "    elif \"ABM-pred-correction\" in params[\"model_name\"]:\n",
    "        # load the param model from ODE\n",
    "        # NOTE: currently it uses only R0\n",
    "        param_model = LearnableParams(ode_param_dim, device, scale_output_ode).to(\n",
    "            device\n",
    "        )\n",
    "    elif \"GradABM-learnable-params\" in params[\"model_name\"]:\n",
    "        param_model = LearnableParams(abm_param_dim, device, scale_output_abm).to(\n",
    "            device\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"model name not valid\")\n",
    "    return param_model\n",
    "\n",
    "def build_simulator(params, devices, counties):\n",
    "    \"\"\"Build simulator: ABM or ODE\"\"\"\n",
    "    if \"ABM\" in params[\"model_name\"]:\n",
    "        if params[\"joint\"]:\n",
    "            abm = {}\n",
    "            # abm devices are different from the ones for the params model\n",
    "            if len(devices) > 1:\n",
    "                abm_devices = devices[1:]\n",
    "            else:\n",
    "                abm_devices = devices\n",
    "            num_counties = len(counties)\n",
    "            for c in range(num_counties):\n",
    "                c_params = copy(params)\n",
    "                c_params[\"county_id\"] = counties[c]\n",
    "                try:\n",
    "                    abm[counties[c]] = GradABM(c_params, abm_devices[c % len(abm_devices)])\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Skipping scenario for {counties[c]}. Parameter file not found.\")\n",
    "                    \n",
    "        else:\n",
    "            if len(devices) > 1:\n",
    "                abm_device = devices[1]\n",
    "            else:\n",
    "                abm_device = devices[0]\n",
    "            abm = GradABM(params, abm_device)\n",
    "    \n",
    "    elif \"ODE\" in params[\"model_name\"]:\n",
    "        disease = params.get('disease', 'DefaultDisease')\n",
    "        if disease == \"COVID\":\n",
    "            abm = SEIRM(params, devices[0])\n",
    "        elif disease == \"Flu\":\n",
    "            abm = SIRS(params, devices[0])\n",
    "        else:\n",
    "            print(\"Invalid disease specified. Using default simulator.\")\n",
    "            abm = DefaultODESimulator(params, devices[0])\n",
    "\n",
    "    return abm\n",
    "\n",
    "def forward_simulator(params, param_values, abm, training_num_steps, counties, devices):\n",
    "    \"\"\"Assumes abm contains only one simulator for COVID (one county), and multiple for flu (multiple counties)\"\"\"\n",
    "\n",
    "    if params[\"joint\"]:\n",
    "        num_counties = len(counties)\n",
    "        predictions = jnp.empty((num_counties, training_num_steps)).to(devices[0])\n",
    "        for time_step in range(training_num_steps):\n",
    "            if \"time-varying\" in params[\"model_name\"]:\n",
    "                param_t = param_values[:, time_step // 7, :]\n",
    "            else:\n",
    "                param_t = param_values\n",
    "            # go over each abm\n",
    "            for c in range(num_counties):\n",
    "                try:\n",
    "                    model_device = abm[counties[c]].device\n",
    "                    population = abm[counties[c]].num_agents\n",
    "                    _, pred_t = abm[counties[c]].step(\n",
    "                        time_step, param_t[c].to(model_device)\n",
    "                    )\n",
    "                    predictions[c, time_step] = pred_t.to(devices[0])\n",
    "                except KeyError:\n",
    "                    print(f\"Skipping county {counties[c]} as simulator object not found.\")\n",
    "                    abm = jnp.array([], device='cuda')\n",
    "                    model_device = 0\n",
    "                    population = 0\n",
    "                    _, pred_t = abm[counties[c]].step(\n",
    "                        time_step, param_t[c].to(model_device)\n",
    "                    )\n",
    "                    predictions[c, time_step] = pred_t.to(devices[0])\n",
    "                    \n",
    "    else:\n",
    "        num_counties = 1\n",
    "        param_values = param_values.squeeze(0)\n",
    "        predictions = []\n",
    "        for time_step in range(training_num_steps):\n",
    "            if \"time-varying\" in params[\"model_name\"]:\n",
    "                param_t = param_values[time_step // 7, :]\n",
    "            else:\n",
    "                param_t = param_values\n",
    "            try:\n",
    "                model_device = abm.device\n",
    "                _, pred_t = abm.step(time_step, param_t.to(model_device))\n",
    "                predictions.append(pred_t.to(devices[0]))\n",
    "            except KeyError:\n",
    "                print(\"Simulator object not found. Skipping simulation.\")\n",
    "        predictions = jnp.stack(predictions, 0).reshape(1, -1)  # num counties, seq len\n",
    "\n",
    "    # post-process predictions for flu\n",
    "    # targets are weekly, so we have to convert from daily to weekly\n",
    "    if params['disease'] == \"Flu\":\n",
    "        predictions = predictions.reshape(num_counties, -1, 7).sum(2)\n",
    "    else:\n",
    "        predictions = predictions.reshape(num_counties, -1)\n",
    "\n",
    "    return predictions.unsqueeze(2)\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax.training import checkpoints\n",
    "from flax.training.common_utils import shard, get_metrics\n",
    "from flax.training.checkpoints import restore_checkpoint\n",
    "from flax.training.common_utils import shard, get_metrics\n",
    "from jax import random\n",
    "\n",
    "def runner(params, devices, verbose):\n",
    "    for run_id in range(params[\"num_runs\"]):\n",
    "        print(\"Run: \", run_id)\n",
    "\n",
    "        # set batch size depending on the number of devices\n",
    "        batch_size = max(len(devices) - 1, 1)\n",
    "\n",
    "        # get data loaders and ground truth targets\n",
    "        if params['disease'] == \"COVID\":\n",
    "            if params[\"joint\"]:\n",
    "                (\n",
    "                    train_loader,\n",
    "                    metas_train_dim,\n",
    "                    X_train_dim,\n",
    "                    seqlen,\n",
    "                ) = fetch_county_data_covid(\n",
    "                    params[\"state\"],\n",
    "                    \"all\",\n",
    "                    pred_week=params[\"pred_week\"],\n",
    "                    batch_size=batch_size,\n",
    "                    noise_level=params[\"noise_level\"],\n",
    "                )\n",
    "            else:\n",
    "                (\n",
    "                    train_loader,\n",
    "                    metas_train_dim,\n",
    "                    X_train_dim,\n",
    "                    seqlen,\n",
    "                ) = fetch_county_data_covid(\n",
    "                    params[\"state\"],\n",
    "                    params[\"county_id\"],\n",
    "                    pred_week=params[\"pred_week\"],\n",
    "                    batch_size=batch_size,\n",
    "                    noise_level=params[\"noise_level\"],\n",
    "                )\n",
    "            params[\"num_steps\"] = seqlen\n",
    "        elif params['disease'] == \"Flu\":\n",
    "            if params[\"joint\"]:\n",
    "                (\n",
    "                    train_loader,\n",
    "                    metas_train_dim,\n",
    "                    X_train_dim,\n",
    "                    seqlen,\n",
    "                ) = fetch_county_data_flu(\n",
    "                    params[\"state\"],\n",
    "                    \"all\",\n",
    "                    pred_week=params[\"pred_week\"],\n",
    "                    batch_size=batch_size,\n",
    "                    noise_level=params[\"noise_level\"],\n",
    "                )\n",
    "            else:\n",
    "                (\n",
    "                    train_loader,\n",
    "                    metas_train_dim,\n",
    "                    X_train_dim,\n",
    "                    seqlen,\n",
    "                ) = fetch_county_data_flu(\n",
    "                    params[\"state\"],\n",
    "                    params[\"county_id\"],\n",
    "                    pred_week=params[\"pred_week\"],\n",
    "                    batch_size=batch_size,\n",
    "                    noise_level=params[\"noise_level\"],\n",
    "                )\n",
    "            params[\"num_steps\"] = seqlen * 7\n",
    "\n",
    "        # add days ahead to num steps because num steps is used for forward pass of param model\n",
    "        training_num_steps = params[\"num_steps\"]\n",
    "        params[\"num_steps\"] += DAYS_HEAD\n",
    "        param_model = build_param_model(\n",
    "            params, metas_train_dim, X_train_dim, devices[0], CUSTOM_INIT=True\n",
    "        )\n",
    "        # filename to save/load model\n",
    "        file_name = \"param_model\" + \"_\" + params[\"model_name\"]\n",
    "        # do not train ABM because it uses a different calibration procedure\n",
    "        train_flag = (\n",
    "            False\n",
    "            if params[\"model_name\"].startswith(\"ABM\") or params[\"inference_only\"]\n",
    "            else True\n",
    "        )\n",
    "\n",
    "        num_epochs = NUM_EPOCHS_DIFF\n",
    "        CLIP = 10\n",
    "        if \"learnable-params\" in params[\"model_name\"]:\n",
    "            lr = 1e-2  # obtained after tuning\n",
    "            num_epochs *= 2\n",
    "        else:\n",
    "            lr = 1e-4 if params[\"model_name\"].startswith(\"GradABM\") else 1e-4\n",
    "\n",
    "        \"\"\" step 1: training  \"\"\"\n",
    "        if train_flag:\n",
    "            assert param_model != None\n",
    "            optimizer_def = flax.optim.Adam(learning_rate=lr, weight_decay=0.01)\n",
    "            optimizer = optimizer_def.create(param_model)\n",
    "            losses = []\n",
    "            rng = jax.random.PRNGKey(0)\n",
    "            for epi in tqdm(range(num_epochs)):\n",
    "                start = time.time()\n",
    "                batch_predictions = []\n",
    "                if verbose:\n",
    "                    print(\"\\n\", \"=\" * 60)\n",
    "                    print(\"Epoch: \", epi)\n",
    "                epoch_loss = 0\n",
    "                print(len(train_loader))\n",
    "                for batch, (counties, meta, x, y) in enumerate(train_loader):\n",
    "                    print(batch, counties)\n",
    "                    # construct abm for each forward pass\n",
    "                    abm = build_simulator(copy(params), devices, counties)\n",
    "                    # forward pass param model\n",
    "                    meta = meta.to(devices[0])\n",
    "                    x = x.to(devices[0])\n",
    "                    y = y.to(devices[0])\n",
    "                    param_values = param_model_forward(param_model, params, x, meta)\n",
    "                    if verbose:\n",
    "                        if param_values.ndim > 2:\n",
    "                            print(param_values[:, [0, -1], :])\n",
    "                        else:\n",
    "                            print(param_values)\n",
    "                    # forward simulator for several time steps\n",
    "                    if BENCHMARK_TRAIN:\n",
    "                        start_bench = time.time()\n",
    "                    predictions = forward_simulator(\n",
    "                        params, param_values, abm, training_num_steps, counties, devices\n",
    "                    )\n",
    "                    if BENCHMARK_TRAIN:\n",
    "                        # quit after 1 epoch\n",
    "                        print(\"No steps:\", training_num_steps)\n",
    "                        print(\"time (s): \", time.time() - start_bench)\n",
    "                        quit()\n",
    "                    # loss\n",
    "                    if verbose:\n",
    "                        print(jnp.concatenate((y, predictions), 2))\n",
    "                    loss_weight = jnp.ones((len(counties), training_num_steps, 1)).to(\n",
    "                        devices[0]\n",
    "                    )\n",
    "                    loss = jnp.mean((loss_weight * jnp.square(y - predictions)).mean())\n",
    "                    grad_fn = jax.value_and_grad(loss_fn)\n",
    "                    optimizer, grad = grad_fn(optimizer, x, y)\n",
    "                    optimizer = optimizer.apply_gradient(grad)\n",
    "                    epoch_loss += jnp.sqrt(loss).item()\n",
    "                    print(\"current Loss is - \", epoch_loss)\n",
    "                losses.append(epoch_loss / (batch + 1))  # divide by number of batches\n",
    "                print(\"total Loss is - \", epoch_loss)\n",
    "                if verbose:\n",
    "                    print(\"epoch_loss\", epoch_loss)\n",
    "\n",
    "                \"\"\" save best model \"\"\"\n",
    "                if epoch_loss < best_loss:\n",
    "                    if params[\"joint\"]:\n",
    "                        save_model(\n",
    "                            param_model,\n",
    "                            file_name,\n",
    "                            params['disease'],\n",
    "                            \"joint\",\n",
    "                            params[\"pred_week\"],\n",
    "                        )\n",
    "                    else:\n",
    "                        save_model(\n",
    "                            param_model,\n",
    "                            file_name,\n",
    "                            params['disease'],\n",
    "                            params[\"county_id\"],\n",
    "                            params[\"pred_week\"],\n",
    "                        )\n",
    "                    best_loss = epoch_loss\n",
    "\n",
    "                print(\"epoch {} time (s): {:.2f}\".format(epi, time.time() - start))\n",
    "\n",
    "        \"\"\" step 2: inference step  \"\"\"\n",
    "        \"\"\" upload best model in inference \"\"\"\n",
    "        param_model = None\n",
    "        abm = None\n",
    "        param_model = build_param_model(\n",
    "            copy(params), metas_train_dim, X_train_dim, devices[0], CUSTOM_INIT=True\n",
    "        )\n",
    "        if not params[\"model_name\"].startswith(\"ABM\"):\n",
    "            # load param model if it is not ABM-expert\n",
    "            if params[\"joint\"]:\n",
    "                param_model = load_model(\n",
    "                    param_model,\n",
    "                    file_name,\n",
    "                    params['disease'],\n",
    "                    \"joint\",\n",
    "                    params[\"pred_week\"],\n",
    "                    devices[0],\n",
    "                )\n",
    "            else:\n",
    "                param_model = load_model(\n",
    "                    param_model,\n",
    "                    file_name,\n",
    "                    params['disease'],\n",
    "                    params[\"county_id\"],\n",
    "                    params[\"pred_week\"],\n",
    "                    devices[0],\n",
    "                )\n",
    "        elif \"ABM-pred-correction\" in params[\"model_name\"]:\n",
    "            # pred-correction, uses param model from ODE\n",
    "            file_name = \"param_model\" + \"_\" + \"DiffODE-learnable-params\"\n",
    "            if params[\"noise_level\"] > 0:\n",
    "                file_name = (\n",
    "                    \"param_model\"\n",
    "                    + \"_\"\n",
    "                    + \"DiffODE-learnable-params\"\n",
    "                    + \"-noise\"\n",
    "                    + str(params[\"noise_level\"])\n",
    "                )\n",
    "            param_model = load_model(\n",
    "                param_model,\n",
    "                file_name,\n",
    "                params['disease'],\n",
    "                params[\"county_id\"],\n",
    "                params[\"pred_week\"],\n",
    "                devices[0],\n",
    "            )\n",
    "\n",
    "        num_step = training_num_steps + DAYS_HEAD\n",
    "        batch_predictions = []\n",
    "        counties_predicted = []\n",
    "        learned_params = []\n",
    "        with torch.no_grad():\n",
    "            for batch, (counties, meta, x, y) in enumerate(train_loader):\n",
    "                # construct abm for each forward pass\n",
    "                abm = build_simulator(params, devices, counties)\n",
    "                # forward pass param model\n",
    "                meta = meta.to(devices[0])\n",
    "                x = x.to(devices[0])\n",
    "                param_values = param_model_forward(param_model, params, x, meta)\n",
    "                # forward simulator for several time steps\n",
    "                preds = forward_simulator(\n",
    "                    params, param_values, abm, num_step, counties, devices\n",
    "                )\n",
    "                batch_predictions.append(preds)\n",
    "                counties_predicted.extend(counties)\n",
    "                learned_params.extend(np.array(param_values.cpu().detach()))\n",
    "        predictions = torch.cat(batch_predictions, axis=0)\n",
    "        # we only care about the last predictions\n",
    "        # predictions are weekly, so we only care about the last 4\n",
    "        if params['disease'] == \"Flu\":\n",
    "            predictions = predictions.squeeze(2)[:, -DAYS_HEAD // 7 :]\n",
    "        else:\n",
    "            predictions = predictions.squeeze(2)[:, -DAYS_HEAD:]\n",
    "        \"\"\" remove grad \"\"\"\n",
    "        predictions = predictions.cpu().detach()\n",
    "\n",
    "        \"\"\" release memory \"\"\"\n",
    "        param_model = None\n",
    "        abm = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \"\"\" plot losses \"\"\"\n",
    "        # only if trained\n",
    "        if train_flag:\n",
    "            disease = params['disease']\n",
    "            if params[\"joint\"]:\n",
    "                FIGPATH = f\"/kaggle/working/Figures/{disease}/joint/\"\n",
    "            else:\n",
    "                county_id = params[\"county_id\"]\n",
    "                FIGPATH = f\"/kaggle/working/Figures/{disease}/{county_id}/\"\n",
    "            if not os.path.exists(FIGPATH):\n",
    "                os.makedirs(FIGPATH)\n",
    "            sns.set()\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.plot(losses)\n",
    "            pred_week = params[\"pred_week\"]\n",
    "            fig.savefig(FIGPATH + f\"/losses_{pred_week}.png\")\n",
    "        print(\"-\" * 60)\n",
    "        return counties_predicted, np.array(predictions), learned_params\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(\n",
    "    disease: str,\n",
    "    model_name: str,\n",
    "    region: str,\n",
    "    pred_week: str,\n",
    "    death_predictions: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given an array w/ predictions, save as csv\n",
    "    \"\"\"\n",
    "    data = np.array([np.arange(len(death_predictions)) + 1, death_predictions])\n",
    "    if disease == \"COVID\":\n",
    "        df = pd.DataFrame(data.transpose(), columns=[\"k_ahead\", \"deaths\"])\n",
    "    elif disease == \"Flu\":\n",
    "        df = pd.DataFrame(data.transpose(), columns=[\"k_ahead\", \"ili\"])\n",
    "    else:\n",
    "        raise ValueError(\"disease must be COVID or Flu\")\n",
    "    df[\"k_ahead\"] = df[\"k_ahead\"].astype(\"int8\")\n",
    "    path = f\"./Results/{disease}/{region}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = f\"preds_{model_name}_{pred_week}.csv\"\n",
    "    df.to_csv(os.path.join(path, file_name), index=False)\n",
    "\n",
    "\n",
    "def save_params(\n",
    "    disease: str,\n",
    "    model_name: str,\n",
    "    region: str,\n",
    "    pred_week: str,\n",
    "    param_values: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given an array w/ predictions, save as csv\n",
    "    \"\"\"\n",
    "    path = f\"./Results/{disease}/{region}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file_name = f\"params_{model_name}_{pred_week}.csv\"\n",
    "    np.savetxt(os.path.join(path, file_name), param_values, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_weeks(disease, model_name, pred_ew, state, county_id, inference_only=False, noise=0, results_file_postfix=\"\"):\n",
    "    pred_week = pred_ew.cdcformat()\n",
    "    try:\n",
    "        counties_predicted, predictions, learned_params = train_predict(\n",
    "            disease=disease,\n",
    "            model_name=model_name,\n",
    "            pred_week=pred_week,\n",
    "            state=state,\n",
    "            county_id=county_id,\n",
    "            inference_only=inference_only,\n",
    "            noise=noise,\n",
    "        )\n",
    "        num_counties = len(counties_predicted)\n",
    "        for c in tqdm(range(num_counties)):\n",
    "            save_predictions(\n",
    "                disease,\n",
    "                model_name,\n",
    "                counties_predicted[c],\n",
    "                str(pred_ew),\n",
    "                predictions[c, :],\n",
    "            )\n",
    "            save_params(\n",
    "                disease,\n",
    "                model_name,\n",
    "                counties_predicted[c],\n",
    "                str(pred_ew),\n",
    "                learned_params[c],\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"exception: did not work for {state} week {pred_ew}: \" + str(e) + \"\\n\")\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage example:\n",
    "run_all_weeks(\n",
    "    disease=\"COVID\",\n",
    "    model_name=\"GradABM-time-varying\",\n",
    "    pred_ew=Week.fromstring(\"202021\"),\n",
    "    state=\"MA\",\n",
    "    county_id=\"25001\",\n",
    "    inference_only=False,\n",
    "    noise=0,\n",
    "    results_file_postfix=\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
